{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RSG_Data Splitter.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPU56wz/Z5YYGh2YayLnb7r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1diqC4dBz1xc"},"source":["# Ready, Steady, Go AI (*Tutorial*)"]},{"cell_type":"markdown","metadata":{"id":"MlQSL0no0uYT"},"source":["This tutorial is a supplement to the paper, **Ready, Steady, Go AI: A Practical Tutorial on Explainable Artificial Intelligence and Its Applications in Plant Digital Phenomics** (submitted to *Patterns, 2021*) by Farid Nakhle and Antoine Harfouche\n","\n","Read the accompanying paper [here](https://doi.org)."]},{"cell_type":"markdown","metadata":{"id":"X5XoL1aD07Qo"},"source":["# Table of contents\n"]},{"cell_type":"markdown","metadata":{"id":"SV7BfDp03T2j"},"source":["* **1. Background**\n","* **2. Downloading the Dataset**\n","* **3. Splitting the Dataset**"]},{"cell_type":"markdown","metadata":{"id":"7btTy9923b9k"},"source":["# 1. Background\n"]},{"cell_type":"markdown","metadata":{"id":"iVEjYGUW3iMI"},"source":["**Why do we need to split?**\n","\n","When training a model for image analysis, an algorithm is presented with image data to learn from. For the model to learn, the algorithm uses a loss function to inform the model how close or far away it is from making a correct prediction. As a result, the model formulates a predicting function based on the feedback it got from the loss function, ultimately mapping pixels in the image to output a prediction.\n","\n","While this works well, the model might learn an overly specific function that performs well on the given images without being able to generalize to new images that it has not seen during its training. This is known as overfitting.\n","\n","The train, validation, and testing splits help us avoid overfitting.\n","\n","Instead of using all data to train, the training set, commonly the largest split of a dataset, will be reserved to train the model.\n","\n","During training, it is important to understand how well the model is doing on images that are not part of training. Here, the validation set is used to report a validation metric that tells us the performance of the model at each traning epoch.\n","\n","After the training have concluded, we might have a hint on the performance of the final model based on reports of the validation set. However, the validation set metrics might have influenced our hyperparameter choices during the creation of the model, and in this sense, we might have accidentally caused an overfit to the validation set.\n","And here comes the role of the test set. The evaluation metrics should be measured on the test set at the very end of the project, to finaly get a real sense of how well a model will perform in production.\n","\n","**What is the best splitting ratio?**\n","\n","\n","There is no exact golden ratio for the splitting. The choice of a split ratio is completely dependent on the dataset. Having more data allows the choice of a bigger portion for the traning set. It is best to experiment with different splitting ratio. This is called cross validation, where 3, 5, 10 or any K number of splits can be done. Those splits are called folds, and there are many strategies used to create these folds. However, this is not in the scope of this tutorial."]},{"cell_type":"markdown","metadata":{"id":"5n-qgOHeBPuO"},"source":["# 2. Downloading the Dataset\n"]},{"cell_type":"markdown","metadata":{"id":"OnMTvK_SBSro"},"source":["As a reminder, we are working with the PlantVillage dataset, originally obtained from [here](http://dx.doi.org/10.17632/tywbtsjrjv.1).\n","For this tutorial, we will be working with a subset of PlantVillage, where we will choose the tomato classes only. We have made the subset available [here](http://dx.doi.org/10.17632/4g7k9wptyd.1). \n","\n","The next code will automatically download the dataset and save it to our current working environment.\n","\n","**It is important to note that Colab deletes all unsaved data once the instance is recycled. Therefore, remember to download your results once you run the code.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2QkBhoIt66D-","executionInfo":{"status":"ok","timestamp":1618225966292,"user_tz":-120,"elapsed":31513,"user":{"displayName":"Farid Nakhle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUlVurX8XdrGra-Jpp6WlS33hxKQHBtkwXwhhwYQ=s64","userId":"13288215553045444657"}},"outputId":"e60935a9-cf62-4201-bb0e-5ce08f2c6c60"},"source":["import requests\n","import os\n","import zipfile\n","\n","## FEEL FREE TO CHANGE THESE PARAMETERS\n","dataset_url = \"http://faridnakhle.com/pv/tomato-original.zip\"\n","save_data_to = \"/content/dataset/\"\n","dataset_file_name = \"dataset.zip\"\n","#######################################\n","\n","if not os.path.exists(save_data_to):\n","    os.makedirs(save_data_to)\n","\n","r = requests.get(dataset_url, stream = True, headers={\"User-Agent\": \"Ready, Steady, Go AI\"})\n","\n","print(\"Downloading dataset...\")  \n","\n","with open(save_data_to + dataset_file_name, \"wb\") as file: \n","    for block in r.iter_content(chunk_size = 1024):\n","         if block: \n","             file.write(block)\n","\n","## Extract downloaded zip dataset file\n","print(\"Dataset downloaded\")  \n","print(\"Extracting files...\")  \n","with zipfile.ZipFile(save_data_to + dataset_file_name, 'r') as zip_dataset:\n","    zip_dataset.extractall(save_data_to)\n","\n","## Delete the zip file as we no longer need it\n","os.remove(save_data_to + dataset_file_name)\n","print(\"All done!\")  \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading dataset...\n","Dataset downloaded\n","Extracting files...\n","All done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MZFcJ7w8ESfL"},"source":["# 3. Splitting the Dataset"]},{"cell_type":"markdown","metadata":{"id":"YeGGr_l4ET6h"},"source":["To split the dataset, we will use split-folders python library to do a random split of 80% for training, 10% for validation, and 10% for testing.\n","split-folders will use a parameter called seed to help reproduce a specific split (instead of getting a new random split every time).\n","\n","To reproduce our results, use the value 1337 for the seed as shown below."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljFSQu3E09Bn","executionInfo":{"status":"ok","timestamp":1618218825096,"user_tz":-120,"elapsed":7362,"user":{"displayName":"Farid Nakhle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUlVurX8XdrGra-Jpp6WlS33hxKQHBtkwXwhhwYQ=s64","userId":"13288215553045444657"}},"outputId":"b43755ad-3ffa-48c8-df5c-34e23a7cf2e4"},"source":["!pip install split-folders tqdm\n","!splitfolders --output \"/content/dataset/tomato-split/\" --seed 1337 --ratio .8 .1 .1 -- \"/content/dataset/\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting split-folders\n","  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.4.3\n","Copying files: 18160 files [00:02, 6226.72 files/s]\n"],"name":"stdout"}]}]}